# Architecture Choices

## System Overview

The voice bot is a server-side application that places outbound phone calls to the Pivot Point Orthopedics AI receptionist, simulates patient conversations in real time, and records transcripts for bug analysis. It is composed of three layers: a telephony layer (Telnyx Call Control), an audio bridge (FastAPI WebSocket server), and a conversational AI layer (OpenAI Realtime API).

When a call is triggered via the CLI, the FastAPI server sends an outbound call request to the Telnyx Call Control API. Telnyx places the call and delivers lifecycle events (answered, hangup) as HTTP webhooks. Once the call is answered, the server instructs Telnyx to begin bidirectional audio streaming over WebSocket using RTP mode with the PCMU codec (G.711 u-law at 8kHz). Simultaneously, the server opens a second WebSocket connection to OpenAI's Realtime API, configured with the same g711_ulaw audio format. The server then acts as a bridge: audio packets from the agent flow from Telnyx into OpenAI, and audio packets generated by the Realtime model flow back from OpenAI into Telnyx and onto the call. No audio transcoding occurs at any point.

The Realtime model is prompted with a patient persona and scenario instructions. It hears the agent's voice, reasons about the conversation, and generates a spoken response. OpenAI's server-side voice activity detection handles turn-taking. Transcripts of both sides are captured via the Realtime API's built-in Whisper transcription and saved to disk when the call ends.

## Key Design Decisions

### Telnyx over Twilio for healthcare privacy

The bot simulates patients discussing sensitive healthcare information: symptoms, medications, insurance details, and appointment history. Telnyx was chosen over Twilio because Telnyx operates its own private IP network and global infrastructure rather than routing voice traffic over the public internet. This provides a stronger privacy posture for handling healthcare-adjacent conversations, even in a testing context. Telnyx also offers lower per-minute rates for outbound calling, which matters when running dozens of test calls during development.

### OpenAI Realtime API over GPT-4o-mini text pipeline

The initial design used a traditional three-stage pipeline: Telnyx's built-in speech-to-text for transcription, GPT-4o-mini for generating text responses, and Telnyx TTS for speaking the response back on the call. This worked but had two significant drawbacks. First, latency compounded across three separate API calls per conversational turn, making the bot sound unnatural with noticeable pauses. Second, converting audio to text and back discarded tonal cues like pacing, hesitation, and emphasis, which are important for realistic patient simulation.

The system was rebuilt around OpenAI's Realtime API, which is a native speech-to-speech model. Audio goes in, audio comes out, with no intermediate text conversion during the response generation step. This reduced turn-to-turn latency significantly and produced more natural-sounding conversations. The model can hear how the agent speaks (not just what it says) and respond with appropriate tone and pacing, which makes it a better tool for stress-testing a voice AI receptionist. The Realtime API also provides built-in Whisper transcription of both sides as a side effect, so transcripts come for free without a separate STT step.

### RTP bidirectional streaming

Telnyx's default WebSocket streaming mode only accepts MP3 for audio sent back to the call, which would require transcoding the Realtime API's g711_ulaw output. Enabling RTP bidirectional mode with the PCMU codec allows raw g711_ulaw audio to pass through in both directions without any format conversion. This eliminates transcoding latency and avoids potential audio quality degradation.

### Scenario-driven testing

Each test call is configured with a structured scenario containing a patient persona, demographic details, and an opening line. Scenarios are defined as plain Python data structures, making it easy to add new test cases without modifying any application logic. The 12 scenarios cover the three capabilities supported by the AI receptionist (appointments, insurance updates, prescription refills) as well as edge cases designed to surface bugs: weekend booking requests, vague patients, mid-call topic switches, contradictory information, urgent injuries, and out-of-scope requests.

## Data Flow

```
Telnyx              FastAPI Server         OpenAI Realtime API
(phone call)        (bridge)               (patient brain)
     |                   |                       |
     |-- call.answered ->|                       |
     |                   |-- streaming_start     |
     |                   |-- ws connect -------->|
     |                   |-- session.update ---->|
     |                   |-- response.create --->|  (triggers opening line)
     |                   |                       |
     |   agent audio --->|--- g711_ulaw -------->|  (agent's voice)
     |                   |                       |
     |                   |<-- g711_ulaw ---------|  (patient response)
     |<-- play audio ----|                       |
     |                   |                       |
     |                   |<-- transcript --------|  (Whisper transcription)
     |                   |                       |
     |-- call.hangup --->|                       |
     |                   |-- save transcript     |
     |                   |-- close ws ---------->|
```
